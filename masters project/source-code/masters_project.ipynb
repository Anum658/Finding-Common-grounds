{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "import networkx as nx\n",
    "from sympy.logic.boolalg import Not, And, Or\n",
    "from sympy.logic.inference import satisfiable\n",
    "from sympy.logic.inference import entails\n",
    "from itertools import *\n",
    "from itertools import combinations\n",
    "import itertools as it\n",
    "import itertools    \n",
    "import copy\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import pycountry\n",
    "from collections import defaultdict\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coherence of Horn Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Entailment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_Hornexpr_entailment(F):\n",
    "    \n",
    "    count = 0\n",
    "    #checck for all the clauses in F\n",
    "    for clause in F:\n",
    "        #expression without that clause\n",
    "        F_without_clause = [x for x in F if x is not clause]\n",
    "        if not entails(clause, F_without_clause):\n",
    "            count +=1\n",
    "    \n",
    "    #if entailment condition is true for all clauses, it satisfies first condition\n",
    "    if count == len(F):\n",
    "        return True\n",
    "    else:\n",
    "        return False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Derivations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Antecedents and consequents of Clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function, that takes input as clause, and extract antacedent and consequent\n",
    "def extract_ant_con(clause):\n",
    "    \n",
    "    if type(clause.args[0]) == And:\n",
    "        antacedent = set(clause.args[0].args)\n",
    "    else:\n",
    "        antacedent = {clause.args[0]}\n",
    "        \n",
    "    consequent = clause.args[1].atoms()\n",
    "        \n",
    "    return antacedent, consequent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excludents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to extract symbols from the clause\n",
    "def extract_symbols(F):\n",
    "    atoms= []\n",
    "    for clause in F:\n",
    "        atoms.append(list(clause.args[0].atoms()))\n",
    "        \n",
    "    flat_list = [item for sublist in atoms for item in sublist]\n",
    "    symbol_list = list(set(flat_list))\n",
    "    \n",
    "    return symbol_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to get excludents of symbols using background knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to get excludents using background knowledge \n",
    "def get_excludents(background_know, atom):\n",
    "\n",
    "    excludent_atoms = []\n",
    "    \n",
    "    #extract symbols from backgroun knowledge\n",
    "    symbol_background_know = extract_symbols(background_know)\n",
    "\n",
    "    #check for all the symbols from backgroun knowledge\n",
    "    for symbol in symbol_background_know:\n",
    "        clause = Implies((symbol & atom), False)\n",
    "        \n",
    "        if clause in background_know:\n",
    "            excludent_atoms.append(symbol)\n",
    "            \n",
    "    return excludent_atoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if two clauses have derivation w.r.t. each other while checking excludents condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function takes input as expression, and two clauses, return true if derivation exists\n",
    "def clauses_derivation(clause1, clause2, F):\n",
    "    \n",
    "    count = 0\n",
    "    ant_clause1 = extract_ant_con(clause1)[0]\n",
    "    ant_clause2 = extract_ant_con(clause2)[0]\n",
    "    \n",
    "    #copy the expression to extend it\n",
    "    copy_expr = copy.deepcopy(F)\n",
    "    copy_expr.extend(ant_clause1)\n",
    "\n",
    "    #check entailment for all the antacedents\n",
    "    for atom in ant_clause2:\n",
    "        if entails(atom, copy_expr):\n",
    "            count +=1\n",
    "            \n",
    "    if count == len(ant_clause2):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to generate all possible combinations of horn expressions\n",
    "def generate_combinations(F):\n",
    "    \n",
    "    # generate combinations of size 2\n",
    "    combinations = list(itertools.combinations(F, 2))\n",
    "    \n",
    "    for comb in combinations:\n",
    "        #removing comination that have same clauses\n",
    "        if comb[0] == comb[1]:\n",
    "            combinations.remove(comb)\n",
    "            \n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check derivation condition for whole Horn Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_Hornexpression_derivation(F):\n",
    "    \n",
    "    count = 0\n",
    "    #generate combinations using funtion\n",
    "    combinations = generate_combinations(F)\n",
    "    \n",
    "    #check for all combinations\n",
    "    for comb in combinations:\n",
    "        if not clauses_derivation(comb[0], comb[1], F) and not clauses_derivation(comb[1], comb[0], F) or comb[0] == comb[1] :\n",
    "            count += 1\n",
    "            \n",
    "    #if derivation condition is true for all the combinations \n",
    "    if count == len(combinations):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check coherence of random clause w.r.t. Horn Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_clause_coherence(F, random_clause):\n",
    "    \n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    \n",
    "    F_without_clause = [x for x in F if x != random_clause]\n",
    "    con_random_clause = next(iter(extract_ant_con(random_clause)[1]))\n",
    "    \n",
    "    if not entails(random_clause, F_without_clause):\n",
    "        \n",
    "        #if all clauses in expression are coherent with the random clause\n",
    "        for clause in F:\n",
    "            con_clause = next(iter(extract_ant_con(clause)[1]))\n",
    "            \n",
    "            if con_clause not in get_excludents(background_know, con_random_clause):               \n",
    "                count1 += 1\n",
    "            \n",
    "                if not clauses_derivation(random_clause, clause, F):\n",
    "                    count2 +=1  \n",
    "                \n",
    "    if count1 == count2:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Horn Expression Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hornExpression_coherence(F, background_know):\n",
    "    \n",
    "    #combine all the functions to check coherence of Horn expression\n",
    "    if check_Hornexpr_entailment(F) and check_Hornexpression_derivation(F):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check cyclic Behavior of Horn Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function checks for cycles in horn expression and returns:\n",
    "1. Same Horn expreesion if there is no cycle.\n",
    "2. If there is a cycle, it removes cycle and returns Horn expression after removing cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cycle(F):\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    G = nx.DiGraph()\n",
    "    for clause in F:\n",
    "        #draw nodes as premises and consequences of implications\n",
    "        G.add_node(clause.args[1])\n",
    "        G.add_node(clause.args[0])\n",
    "        G.add_edge(clause.args[0],clause.args[1])\n",
    "    \n",
    "    #draw graphs to check cycles\n",
    "    options = {\"edgecolors\": \"tab:gray\", \"node_size\": 2550, \"alpha\": 0.9,\"font_size\": 13}\n",
    "    pos = nx.shell_layout(G)\n",
    "    nx.draw(G, pos, **options, with_labels = True, node_color=\"tab:pink\",arrowsize=20, edge_color = 'green')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    #detect cycle in graph\n",
    "    if nx.is_directed_acyclic_graph(G):\n",
    "        print('\\n-----------------------------This expression has no cycles-----------------------------\\n')\n",
    "        return F\n",
    "    \n",
    "    #remove the cycle clause\n",
    "    else:\n",
    "        #check for cycles until no cycle is left\n",
    "        while not nx.is_directed_acyclic_graph(G):\n",
    "            cycle = nx.find_cycle(G, orientation=\"original\")\n",
    "            print('This expression has cycle: ', cycle)\n",
    "            \n",
    "            #last edge of the cycle\n",
    "            tuple_clause = cycle[-1][:-1]\n",
    "            print(tuple_clause)\n",
    "            clause_to_remove = Implies(tuple_clause[0], tuple_clause[1])\n",
    "            \n",
    "            #remove last edge(clause) to remove cycle\n",
    "            expr_without_cycle = [x for x in F if x != clause_to_remove]\n",
    "\n",
    "        print('\\n-------------------------------------------------------')\n",
    "        print('\\n Horn Expression after removing cycle is: ')\n",
    "        return expr_without_cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Redundancy of Horn Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function checks redundancy of a Horn expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_redundant_expr(F):\n",
    "    \n",
    "    count = 0\n",
    "    for clause in F: \n",
    "        \n",
    "        #hornexpression without that clause\n",
    "        expr_without_clause = [x for x in F if x != clause]\n",
    "        \n",
    "        if not entails(clause, expr_without_clause):\n",
    "            count +=1\n",
    "    \n",
    "    if count == len(F):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function runs until a expression becomes non-redundant after removing redundant clauses from the horn expression, one clause for each iteration of while loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_redundancy(F):\n",
    "         \n",
    "    if non_redundant_expr(F):\n",
    "        print('\\n-------------------------This Horn Expression already is Non-Redundant-------------------------\\n')\n",
    "        return F\n",
    "    else:\n",
    "    #check for all the clauses\n",
    "        for clause in F: \n",
    "\n",
    "            #hornexpression without that clause\n",
    "            expr_without_clause = [x for x in F if x != clause]\n",
    "\n",
    "            if entails(clause, expr_without_clause):\n",
    "\n",
    "                #update F as without the clause\n",
    "                F = expr_without_clause\n",
    "\n",
    "                #check non redundancy of updated expression\n",
    "                while non_redundant_expr(F):\n",
    "                    \n",
    "                    print('\\n-------------------------This Horn Expression is Non-Redundant now-------------------------\\n')\n",
    "\n",
    "                    return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conflict In Horn Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check conflict between two specific clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function takes clauses as input and check conflict in between them\n",
    "def check_conflict_clauses(F, clause1, clause2, background_know):\n",
    "    \n",
    "    ant_clause1 = extract_ant_con(clause1)[0]\n",
    "    ant_clause2 = extract_ant_con(clause2)[0]\n",
    "    \n",
    "    #remove ant of clause 1 from ant of clause 2\n",
    "    ant_diff = [x for x in ant_clause1 if x not in ant_clause2]\n",
    "    if len(ant_diff) != 0:\n",
    "        for atom in ant_diff:\n",
    "            excludent_atom = get_excludents(background_know, atom)\n",
    "            \n",
    "            for i in excludent_atom:\n",
    "                add_ant_to_clause = Implies((clause2.args[0] & i), clause2.args[1])\n",
    "                F_without_clause = [x for x in F if x != clause2]\n",
    "                \n",
    "                if check_clause_coherence(F_without_clause, add_ant_to_clause):\n",
    "                    return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Horn expression conflict by checking conflict between each possile combination of clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_conflict_expr(F, background_know):\n",
    "    \n",
    "    count = 0\n",
    "    combinations_expr = generate_combinations(F)\n",
    "    \n",
    "    for clause in combinations_expr:\n",
    "        \n",
    "        con_clause1 = next(iter(extract_ant_con(clause[0])[1]))\n",
    "        con_clause2 = next(iter(extract_ant_con(clause[1])[1]))\n",
    "        \n",
    "        #check conflict between every to clauses\n",
    "        if check_conflict_clauses(F, clause[0], clause[1], background_know) and clauses_derivation(clause[0], clause[1], F) and con_clause1 in get_excludents(background_know, con_clause2):\n",
    "            count +=1\n",
    "            \n",
    "    if count > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolve Conflict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can resolve conflict by:\n",
    "1. Check conflict between each possible combination of clauses of horn expression.\n",
    "2. If it is found, resolve by most general symbol using collection of symbols associated with each clause, and background knowledge 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_conflict(F, background_know, col_symbols, background_know_2):\n",
    "    \n",
    "    #copy expression to update it\n",
    "    copy_expr = copy.deepcopy(F)\n",
    "    \n",
    "    while check_conflict_expr(copy_expr, background_know):\n",
    "\n",
    "        #clauses = generate_combinations(F)\n",
    "        dict_of_clauses = {i : copy_expr[i] for i in range(0, len(copy_expr))}\n",
    "\n",
    "        for i in generate_combinations(dict_of_clauses):\n",
    "\n",
    "            clause1 = dict_of_clauses[i[0]]\n",
    "            clause2 = dict_of_clauses[i[1]]\n",
    "            \n",
    "            #extract concludents of clauses\n",
    "            con_clause1 = next(iter(extract_ant_con(clause1)[1]))\n",
    "            con_clause2 = next(iter(extract_ant_con(clause2)[1]))\n",
    "            \n",
    "\n",
    "            #check conflict between two clauses\n",
    "            if check_conflict_clauses(copy_expr, clause1, clause2, background_know) and clauses_derivation(clause1, clause2, copy_expr) and con_clause1 in get_excludents(background_know, con_clause2):\n",
    "                print(clause1, clause2)\n",
    "                for region in background_know_2:\n",
    "                    \n",
    "                    #for first iteration it would replace by most general symbol\n",
    "                    if clause2 in F:\n",
    "                        if col_symbols[i[1]] in region.args:\n",
    "                            update_ant = clause2.replace(clause2.args[0], And(clause2.args[0], region.args[1]))\n",
    "\n",
    "                        #and update the expression\n",
    "                            copy_expr[i[1]] = update_ant\n",
    "                    \n",
    "                    #for the next iteration if conflict exists, it would replace general by specific one\n",
    "                    else:\n",
    "                        if clause1.args[0].atoms().intersection(region.args[1].atoms()) == clause2.args[0].atoms().intersection(region.args[1].atoms()):\n",
    "                            clause1 = clause1.subs(region.args[1], col_symbols[i[0]])\n",
    "                            clause2 = clause2.subs(region.args[1], col_symbols[i[1]])\n",
    "\n",
    "                        copy_expr[i[0]] = clause1\n",
    "                        copy_expr[i[1]] = clause2\n",
    "\n",
    "    #return non repititve expression\n",
    "    return [*set(copy_expr)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolve Incoherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safe pairse of clauses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We search for safe pair using dependancy graphs, in case of incoherence, that we can modify to change expression into Coherent one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_safe_pairs(F):\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    G = nx.DiGraph()\n",
    "    clauses = list(itertools.combinations(F, 2))\n",
    "    inverted_clauses = [t[::-1] for t in clauses]\n",
    "\n",
    "    indices = list((i+1,j+1) for ((i,_),(j,_)) in itertools.combinations(enumerate(F), 2))\n",
    "    selected_clauses = []\n",
    "    options = {\"edgecolors\": \"tab:gray\", \"node_size\": 2550, \"alpha\": 0.9,\"font_size\": 13, }\n",
    "    \n",
    "    for i in range(len(clauses)):\n",
    "        #first we add vertices of dependancy graph\n",
    "        if clauses[i][0].args[1] in get_excludents(background_know, clauses[i][1].args[1]) and (clauses_derivation(clauses[i][0],clauses[i][1],F) or clauses_derivation(clauses[i][1],clauses[i][0],F)):\n",
    "            selected_clauses.append(clauses[i])\n",
    "            G.add_node((indices[i][1], indices[i][0]))\n",
    "    \n",
    "    #invert clasues to update second clause of pair \n",
    "    inverted_clauses = [t[::-1] for t in selected_clauses]\n",
    "    s_clauses = generate_combinations(inverted_clauses)\n",
    "    \n",
    "    for clause in s_clauses:\n",
    "        if next(iter(extract_ant_con(clause[0][1])[1])) in extract_ant_con(clause[1][1])[0] and bool(extract_ant_con(clause[0][0])[0] & extract_ant_con(clause[1][0])[0]):\n",
    "            G.add_edge((F.index(clause[0][0])+1,F.index(clause[0][1])+1),(F.index(clause[1][0])+1,F.index(clause[1][1])+1))\n",
    "            \n",
    "        elif next(iter(extract_ant_con(clause[1][1])[1])) in  extract_ant_con(clause[0][1])[0] and bool(extract_ant_con(clause[0][0])[0] & extract_ant_con(clause[1][0])[0]):\n",
    "            G.add_edge((F.index(clause[1][0])+1,F.index(clause[1][1])+1), (F.index(clause[0][0])+1,F.index(clause[0][1])+1))\n",
    "            \n",
    "    #pos = nx.shell_layout(G)\n",
    "    #nx.draw(G, pos, with_labels = True, **options, node_color=\"tab:pink\",arrowsize=20, edge_color = 'green')\n",
    "    #plt.axis(\"off\")\n",
    "    #plt.show()\n",
    "    non_safe_pairs = []\n",
    "    safe_pairs = [] \n",
    "    for node in G:\n",
    "        if not list(G.predecessors(node)):\n",
    "            safe_pairs.append((F[node[0]-1], F[node[1]-1]))\n",
    "            #print('Safe pair is: ',node)\n",
    "        else:\n",
    "            non_safe_pairs.append(node)\n",
    "            \n",
    "    if len(non_safe_pairs) == G.number_of_nodes():\n",
    "        print('There is no safe pairs')\n",
    "        return False\n",
    "    else:\n",
    "        return safe_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get weaker Version of Clause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get weaker Version of Clauses that we can use for safe pairse to make expression coherent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weaker_version_clause(F, clause1, clause2):\n",
    "    \n",
    "    ant_clause1 = extract_ant_con(clause1)[0]\n",
    "    ant_clause2 = extract_ant_con(clause2)[0]\n",
    "    \n",
    "    ant_diff = [x for x in ant_clause1 if x not in ant_clause2]\n",
    "    #if there is no difference in antacedents, we call for recursion\n",
    "    if len(ant_diff) == 0:\n",
    "        return weaker_version_clause(F, clause2, clause1)\n",
    "    else:\n",
    "        excludent_atom = get_excludents(background_know, ant_diff[0])\n",
    "        for i in excludent_atom:\n",
    "            weaker_clause = Implies(clause2.args[0] & i, clause2.args[1])\n",
    "            F_without_clause = [x for x in F if x != clause2]\n",
    "            \n",
    "            #if weaker clause is coherent with horn expression without clause, we return indices if same clauses is occuring\n",
    "            # in more than one indices\n",
    "            if check_clause_coherence(F_without_clause, weaker_clause):\n",
    "                indices = [i for i, x in enumerate(F) if x == clause2]\n",
    "                return weaker_clause, indices\n",
    "            else:\n",
    "                return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Coherent Horn Expression Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_ground(F, background_know, background_know_2, col_symbols):\n",
    "    \n",
    "    #check if F is acyclic, it returns acyclic F, even if it has cycles\n",
    "    F = check_cycle(F)   \n",
    "    \n",
    "    #check if F is non redundnant, it returns non redundant F  \n",
    "    F =  check_redundancy(F)\n",
    "    \n",
    "    #check if F has conflict\n",
    "    if not check_conflict_expr(F, background_know):\n",
    "        \n",
    "        print('\\n----------------------------- F is not in conflict -----------------------------\\n')\n",
    "    \n",
    "    #if it has, resolve conflict\n",
    "    else:\n",
    "        F = resolve_conflict(F, background_know, col_symbols, background_know_2)\n",
    "        \n",
    "        print('\\n----------------------------- Conflict is resolved -----------------------------\\n', F)\n",
    "    \n",
    "    #check if expression is coherent and run a while loop, until expression becomes coherent\n",
    "    while not hornExpression_coherence(F, background_know):\n",
    "        \n",
    "        print('\\n----------------------------- Resolving Incoherence -----------------------------\\n')\n",
    "\n",
    "        #extract safe pair from F\n",
    "        safe_pairs =  get_safe_pairs(F)\n",
    "        for safe_pair in safe_pairs:\n",
    "            \n",
    "            #divide safe clause into two clauses\n",
    "            clause1 = safe_pair[0]\n",
    "            clause2 = safe_pair[1]\n",
    "\n",
    "            #generate weaker version of clauses\n",
    "            weaker_version, indices = weaker_version_clause(F, clause1, clause2)\n",
    "            \n",
    "            #track the indices and update the clause\n",
    "            F = [weaker_version if F.index(x) in indices else x for x in F]\n",
    "\n",
    "    print('\\n----------------------------- Expression is coherent now -----------------------------\\n')\n",
    "    return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moral Machine Experiment Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset from csv file\n",
    "df = pd.read_csv(r\"SharedResponses-mix.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping Random and none values from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.ScenarioType != 'Random']\n",
    "df = df.dropna(subset = ['UserCountry3'])\n",
    "df = df.dropna(subset = ['ScenarioType'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change country names 3 letters code to full name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_name = []\n",
    "for code in df['UserCountry3']:\n",
    "    full_name.append(pycountry.countries.get(alpha_3=code).name.lower().replace(\" \", \"\"))\n",
    "df.loc[:,'UserCountry3'] = full_name\n",
    "\n",
    "#data columns to lower case\n",
    "df['AttributeLevel'] = df['AttributeLevel'].str.lower()\n",
    "df['ScenarioType'] = df['ScenarioType'].str.lower()\n",
    "df['AttributeLevel'] = df['AttributeLevel'].str.replace('hoomans','humans')\n",
    "df.replace(\"social status\", \"socialstatus\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter dataset according to frequency of scenerios for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_data(df, countries_list):\n",
    "    \n",
    "    #Filter dataset based on list of countries\n",
    "    dataset = df[(df.UserCountry3.isin(countries_list))]\n",
    "    \n",
    "    #filtering data for pedistrains only, green and red signals only\n",
    "    dataset = dataset[dataset.PedPed == 1]\n",
    "    dataset = dataset[(dataset.CrossingSignal == 1) | (dataset.CrossingSignal == 2)]\n",
    "    \n",
    "    #group data based on same column value\n",
    "    dataset = dataset.groupby(['CrossingSignal','ScenarioType','AttributeLevel','UserCountry3','Saved']).size().reset_index(name='Count')\n",
    "    dataset = dataset[dataset.duplicated(subset=['ScenarioType','AttributeLevel'], keep=False)]\n",
    "    \n",
    "    #we only keep the rules with highest frequency occuring in dataset\n",
    "    dataset = dataset.sort_values('Count', ascending=False).drop_duplicates(['CrossingSignal','ScenarioType','AttributeLevel','UserCountry3']).sort_index()\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get clauses from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clauses(data):\n",
    "    \n",
    "    clauses = []\n",
    "    symbols_col = []\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        if row[\"CrossingSignal\"] == 1:\n",
    "            row[\"CrossingSignal\"] = symbols('green')\n",
    "        else:\n",
    "            row[\"CrossingSignal\"] = symbols('red')\n",
    "        row[\"ScenarioType\"] = symbols(row[\"ScenarioType\"])\n",
    "        row[\"AttributeLevel\"] = symbols(row[\"AttributeLevel\"])\n",
    "        row[\"UserCountry3\"] = symbols(row[\"UserCountry3\"])   \n",
    "        if row[\"Saved\"] == 1:\n",
    "            row[\"Saved\"] = symbols('saved')\n",
    "        else:\n",
    "            row[\"Saved\"] = symbols('not_saved')\n",
    "        clauses.append(Implies((row[\"CrossingSignal\"] & row[\"ScenarioType\"] & row[\"AttributeLevel\"]), (row[\"Saved\"])))\n",
    "        \n",
    "        #countriy name is associated with each clause\n",
    "        symbols_col.append(row[\"UserCountry3\"])\n",
    "        \n",
    "    return clauses, symbols_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Horn expression and symbols collection from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define countries as part of regions\n",
    "\n",
    "countries_dict = {'west': ['norway'],\n",
    "                 'east': ['india'],\n",
    "                 'south': ['france']}\n",
    "\n",
    "\n",
    "countries_list = [item for sublist in list(countries_dict.values()) for item in sublist]\n",
    "\n",
    "\n",
    "#we define backgound knowledege 2 as definite clauses, where country name implies region, so specfic symbol to general one\n",
    "background_know_2 = []\n",
    "for key in countries_dict:\n",
    "    for value in countries_dict[key]:\n",
    "        background_know_2.append(Implies(symbols(value), symbols(key)))\n",
    "                  \n",
    "\n",
    "#getting horn expression and collection of symbols using dataset and countries names list\n",
    "horn_expression, collection_of_symbols =  get_clauses(get_filtered_data(df, countries_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring Symbols and defining background knowledge for each symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare all symbols\n",
    "india, not_india, norway, not_norway, france, not_france, east, west, south, not_east, not_west, not_south,\\\n",
    "saved, not_saved, fit, female, old, more, low, humans, less, male, pets, fat, young, high, green, red, fitness,\\\n",
    "gender, age, utilitarian, socialstatus, species \n",
    "= symbols('india, not_india, norway, not_norway, france, not_france, east, west, south,\\\n",
    "not_east, not_west, not_south, saved, not_saved, fit, female, old, more, low, humans, less, male, pets,\\\n",
    "fat, young, high, green, red, fitness, gender, age, utilitarian, socialstatus, species')\n",
    "\n",
    "\n",
    "#defining background knowledge as non definite Horn clauses\n",
    "background_know = [Implies(fitness & gender, False), Implies(fitness  & age, False),\n",
    "                  Implies(fitness & utilitarian, False), Implies(fitness & socialstatus, False),\n",
    "                  Implies(fitness & species, False), Implies(gender & age, False),\n",
    "                  Implies(gender & utilitarian, False), Implies(gender & socialstatus, False), \n",
    "                  Implies(gender & species, False), Implies(age & utilitarian, False), \n",
    "                  Implies(age & socialstatus, False), Implies(age & species, False), \n",
    "                  Implies(utilitarian &  socialstatus, False), Implies(utilitarian & species, False),\n",
    "                  Implies(socialstatus & species, False), Implies(saved & not_saved, False),\n",
    "                  Implies(female & male, False), Implies(old & young, False), \n",
    "                  Implies(more & less, False), Implies(low & high, False), \n",
    "                  Implies(humans & pets, False), Implies(fit & fat, False), \n",
    "                  Implies(green & red, False), Implies(france & not_france, False),\n",
    "                  Implies(india & not_india, False), Implies(norway & not_norway, False),\n",
    "                  Implies(east & not_east, False), Implies(west & not_west, False), \n",
    "                  Implies(south & not_south, False)\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Algorithm on dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use any set of countries and add background knowledge of countries accordingly to find a common ground for countries' dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "find_common_ground(horn_expression, background_know, background_know_2, collection_of_symbols)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"The time of execution of above program is :\",\n",
    "      (end-start) * 10**3, \"ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
